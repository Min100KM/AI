# -*- coding: utf-8 -*-
"""Yezak_art.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JXn_fe3y7EXZ225d-phNfVcEhFDGTJ1M

#ResNet18 로 명화 분류

# 1. 필요 라이브러리 임포트
"""

# Commented out IPython magic to ensure Python compatibility.
# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import json
import os
from tqdm import tqdm, tqdm_notebook
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
from torchvision.datasets import ImageFolder
from torchvision.transforms import ToTensor
from torchvision.utils import make_grid
from torch.utils.data import random_split
from torch.utils.data.dataloader import DataLoader
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
# %matplotlib inline


images_dir = 'C:\\Users\\SeungMin\\PycharmProjects\\YeZak_Project\\YeZak_Dataset_2\\YeZak_Dataset_2'

transform = transforms.Compose([ 
      transforms.Resize((224,224)),
      transforms.RandomHorizontalFlip(),
      transforms.ToTensor(),
      #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
      ])
dataset = ImageFolder(images_dir, transform = transform)   #from torchvision.datasets import ImageFolder
dataset.classes

from google.colab import drive
drive.mount('/content/drive')

"""데이터셋 잘 불러왔는지 확인

transpose(a,b) : a차원과 b차원을 교환 

"""

def visualize_sample(sample):
    print("Class is:", sample[1])
    plt.imshow(sample[0].transpose(0, 1).transpose(1, 2))    # sample[0] 텐서는 (3, 100, 100) 으로 [channel, width, height] 인데, imshow의 인자는 [height, width, channel]순이여야함

visualize_sample(dataset[0])

visualize_sample(dataset[2000])

"""#검증을 위한 데이터 분할"""

train_length = round(len(dataset) * 0.7)
val_length = len(dataset) - train_length             #3971data 중 70퍼가 train data, 30퍼가 test data
train, val = random_split(dataset, [train_length, val_length])      #datase   t에서 랜덤하고 겹치지 않게 주어진 길이만큼 이미지는 쪼갠다 
print(len(dataset))

visualize_sample(train[0])        #랜덤하게 나눴으니까 실행마다 바뀜

visualize_sample(val[0])

"""#모델 학습 준비"""

#gpu 사용 가능한지 확인하기

if torch.cuda.is_available():
    device = "cuda"
else:
    device = "cpu"    #colab GPU사용량 초과해서 cpu사용 -> false출력
    
print(torch.cuda.is_available())

"""resnet18('Weights','none') : weights: class에 대한 가중치(입력안하니까 정확도 낮아서 입력함),  pretrained = none :  pretrained = True 면 다른 큰 데이터셋에서 train되었던 resnet 을 가져옴"""

def get_files_count(folder_path):
  dirListing = os.listdir(folder_path)
  return len(dirListing)

if __name__ =="__main__":
  print(get_files_count("."))

"""https://stackoverflow.com/questions/71538030/weight-tensor-should-be-defined-either-for-all-1000-classes-or-no-classes-but-go
오류 stackoverflow!!!
"""

model = models.resnet18(True).to(device)

def append_dropout(model, rate=0.2):
        for name, module in model.named_children():
            if len(list(module.children())) > 0:
                append_dropout(module)
            if isinstance(module, nn.ReLU):
                new = nn.Sequential(module, nn.Dropout2d(p=rate, inplace=False))
                setattr(model, name, new)


append_dropout(model)


model.fc = nn.Linear(512, 7)         #이거 없으면 처음엔 class1000 으로 나와서,, model.fc 

print(model)

datapath_1 = "/content/drive/MyDrive/ml_workplace/YeZak/YeZak_Dataset_2/동양화, 서예, 수묵화"
datapath_2 = "/content/drive/MyDrive/ml_workplace/YeZak/YeZak_Dataset_2/사실주의"
datapath_3 = "/content/drive/MyDrive/ml_workplace/YeZak/YeZak_Dataset_2/애니메이션(일러스트풍)"
datapath_4 = "/content/drive/MyDrive/ml_workplace/YeZak/YeZak_Dataset_2/연필초상화"
datapath_5 = "/content/drive/MyDrive/ml_workplace/YeZak/YeZak_Dataset_2/인상주의"
datapath_6 = "/content/drive/MyDrive/ml_workplace/YeZak/YeZak_Dataset_2/추상화"
datapath_7 = "/content/drive/MyDrive/ml_workplace/YeZak/YeZak_Dataset_2/팝아트"

weight_1 = get_files_count(datapath_1)
weight_2 = get_files_count(datapath_2)
weight_3 = get_files_count(datapath_3)
weight_4 = get_files_count(datapath_4)
weight_5 = get_files_count(datapath_5)
weight_6 = get_files_count(datapath_6)
weight_7 = get_files_count(datapath_7)

arts_num = {'name' : ['동양화', '사실주의', '애니메이션', '연필초상화', '인상주의','추상화', '팝아트'],
               'num' : [weight_1, weight_2, weight_3, weight_4, weight_5, weight_6, weight_7]}

arts = pd.DataFrame(arts_num)

#print(arts)

arts['class_weight'] = arts.num.sum() / (arts.shape[0] * arts.num)

# print("arts.num = ", arts.num)

# print("arts.num.sum() = ", arts.num.sum())

# print("arts.shape[0] = ", arts.shape[0])

# print("arts.shape[0] * arts.num = ", arts.shape[0] * arts.num)


print(arts)

#arts_weights = arts['class_weight'].to_dict() 

arts_weights = arts['class_weight']


print(arts['class_weight'])

class_weights = torch.FloatTensor(arts_weights).to(device)     #손실함수에 넣어보기

print(class_weights)

#model = models.resnet18(arts_weights).to(device)   #resnet 18사용, weight 입력

criterion = torch.nn.CrossEntropyLoss(weight = class_weights)   #손실함수(loss function) 선택, 예측값과 실제값의 차이를 구한다.
optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)  # 최적화 모델 선택, 모델의 매개변수(model.parameters())를 조정해서 모델을 최적화 시킨다.     

# scheduler = optimizer.lr_scheduler.LambdaLR(optimizer=optimizer,
#                                         lr_lambda=lambda epoch: 0.95 ** epoch,
#                                         last_epoch=-1,
#                                         verbose=False)

#optim.SGD : 옵티마이저 중 stochastic gradient descent
#lr : learning rate     낮으면 학습 느리고, 너무 크면 overfitting 일어나서 오차 커짐
#속도 느려서 lr 0.01로 하니까 overfitting 일어남. 0.001이 딱 좋은듯=> 추후조정

BATCH_SIZE = 16     #GPU안돌아가서 배치 32-> 16으로 줄임
train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)

#batch : 학습의 한 반복자(iter)를 epoch이라 하는데, 한 epoch에 들어가는 data의 수를 batchsize 라 한다
#DataLoader : batchsize 에 맞게 iterable한 객체로 dataset 에 접근한다.  -> for x, y in dataloader 표현 가능

model.to(device)
criterion.to(device)

"""#모델 평가"""

def get_accuracy(model, loader):   #모델의 정확도를 구하는 함수
    model.eval()                  #resnet과 같은 model은 eval() <- 평가모드 와 train() <- 학습모드로 지정함에 따라 필요한 매개변수를 키고 끌 수 있으니 항상 적절하게 바꿔줘야함
    total = 0                     #loader의 전체 데이터수를 담을 변수
    correct = 0                   #모델의 정확도를 담을 변수
    for x, y in tqdm(loader):     # dataloader는 한 iter에 batchsize 만큼의 데이터를 가져옴, 만약 batchsize가 k라면   x : feature [k, 10, , ] <-- 10은 class수   y : lable [k] 의 size를 가질거임  
        x = x.to(device)

        y = y.to(device)
        
        pred = model(x)           #feature을 model에 넣어 prediction값 구하기, 

        total += y.shape[0]       #shape[0] : 행의 갯수, 즉 batchsize가 됨
        correct += (y == pred.argmax(1)).sum().item()     #일치정도를 구하는 방법 : pred.argmax(1) => pred의 1차원 ([k, 10, , ]에서 10인 class에 해당)중 값이 가장 큰 것이 몇 번째인지 알려줌. 즉 측정한 class알려줌
                                                          #y은 label이니까 한 batch의 k개의 데이터 중 label = 예측값 인거 찾기
                                                          #.sum()은 해당 조건 만족하는 갯수, .item()은 scalar 값으로 표현
        
        #print("pred.argmax(1) = ", pred.argmax(1))
        
        #print("pred.argmax(1).size = ", pred.argmax(1).size())
        
        #print("pred.argmax(1).max = ", pred.argmax(1).max())
        
        #print("y ", y)   디버그용
        
    return correct / total          #예측과 일치한 데이터 수 / 전체 데이터 수

get_accuracy(model, val_loader)         # train전에 확인

"""#모델 학습

학습 3단계 1. optimizer초기화, 2. loss.backwards() <- background propagation 3. optimizer.step()가중치갱신
"""

def train_epoch(model, loader, loss_list, accuracy_list):      #한 epoch에 모델학습하는 함수

    total = 0
    correct = 0
    total_loss = 0

    loss_list = []
    accuracy_list = []

    for x, y in tqdm(loader):
        optimizer.zero_grad()      # optimizer 파라미터 초기화    
        x = x.to(device)
        y = y.to(device)
        pred = model(x)           #예측값
        loss = criterion(pred, y)     #loss계산하고
        loss.backward()             # background propagation   각 매개변수에 대한 손실의 변화도 저장

        total += y.shape[0]
        correct += (y == pred.argmax(1)).sum().item()
        total_loss += loss.item()

        optimizer.step()        #background propagation 결과로 parameter새로 업뎃

    accuracy = correct / total
    average_loss = total_loss / len(loader)

    loss_list.append(average_loss)
    accuracy_list.append(accuracy)
    
    return accuracy, average_loss

best_val_acc = 0
loss_list = []
accuracy_list = []

epochs = np.arange(1, 20)

for epoch in epochs:
    
    print("Epoch {}".format(epoch + 1).center(40).center(80, "#"))
    train_acc, train_loss = train_epoch(model, train_loader, loss_list, accuracy_list)
    val_acc = get_accuracy(model, val_loader)
    
    print("train_acc={:.5f} train_loss={:.5f} val_acc={:.5f}".format(train_acc, train_loss, val_acc))
    
    if val_acc > best_val_acc:            # 만약 새로운 epoch에 더 좋은 정확도 나오면 모델 새로 저장
        best_val_acc = val_acc
        torch.save(model.state_dict(), "/content/drive/MyDrive/ml_workplace/YeZak/model.pt")
        print("Saved model to `model.pt`")

epochs = np.arange(1, 20)

loss_list = np.arange(1, 20)

accuracy_list = np.arange(1, 20)

plt.figure(figsize=(10,5))
plt.subplot(1,2,1)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.plot(epochs,loss_list)
plt.subplot(1,2,2)
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.plot(epochs, accuracy_list)
plt.show()

torch.save(model.state_dict(), "/content/drive/MyDrive/ml_art_prac/model.pt")    #모델 저장하기

"""# Sanity Test 검증단계"""

model.load_state_dict(torch.load("/content/drive/MyDrive/ml_art_prac/model.pt", map_location="cpu"))    #모델 불러오기

model = model.to(device)

get_accuracy(model, val_loader)

from PIL import Image

def print_label(prediction):
  if prediction == 0:
      print("동양화입니다.")
  elif prediction == 1:
      print("사실주의입니다.")
  elif prediction == 2:
      print("애니메이션입니다.")
  elif prediction == 3:
      print("연필초상화입니다.")
  elif prediction == 4:
      print("인상주의입니다.")
  elif prediction == 5:
      print("추상화입니다.")
  elif prediction == 6:
      print("팝아트입니다.")

image = Image.open("/content/drive/MyDrive/images/test_set/현대인상주의_1.jpg")
image

image = transform(image)
model = model.to("cpu")
model.eval()

prediction = model(image.unsqueeze(0))
#print(prediction)
prediction = prediction.argmax()

model.fc._parameters

print_label(prediction)

image = Image.open("/content/drive/MyDrive/images/test_set/현대인상주의_2.jpg")
image

image = transform(image)
model = model.to("cpu")
model.eval()

prediction = model(image.unsqueeze(0))
#print(prediction)
prediction = prediction.argmax()

model.fc._parameters

print_label(prediction)

image = Image.open("/content/drive/MyDrive/images/test_set/팝아트_1.jpg")
image

image = transform(image)
model = model.to("cpu")
model.eval()

prediction = model(image.unsqueeze(0))
#print(prediction)
prediction = prediction.argmax()

model.fc._parameters

print_label(prediction)

image = Image.open("/content/drive/MyDrive/images/test_set/사실주의_2.jpg")
image

image = transform(image)
model = model.to("cpu")
model.eval()

prediction = model(image.unsqueeze(0))
#print(prediction)
prediction = prediction.argmax()

model.fc._parameters

print_label(prediction)

image = Image.open("/content/drive/MyDrive/ml_workplace/YeZak/test_set/애니메이션_1.jpg")
image

image = transform(image)
model = model.to("cpu")
model.eval()

prediction = model(image.unsqueeze(0))
#print(prediction)
prediction = prediction.argmax()

model.fc._parameters

print_label(prediction)

image = Image.open("/content/drive/MyDrive/ml_workplace/YeZak/test_set/팝아트_1.jpg")
image

image = transform(image)
model = model.to("cpu")
model.eval()

prediction = model(image.unsqueeze(0))
#print(prediction)
prediction = prediction.argmax()

model.fc._parameters

print_label(prediction)

image = Image.open("/content/drive/MyDrive/ml_workplace/YeZak/test_set/현대인상주의_1.jpg")
image

image = transform(image)
model = model.to("cpu")
model.eval()

prediction = model(image.unsqueeze(0))
#print(prediction)
prediction = prediction.argmax()

print_label(prediction)

image = Image.open("/content/drive/MyDrive/ml_workplace/YeZak/test_set/현대인상주의_2.jpg")
image

image = transform(image)
model = model.to("cpu")
model.eval()

prediction = model(image.unsqueeze(0))
#print(prediction)
prediction = prediction.argmax()

print_label(prediction)